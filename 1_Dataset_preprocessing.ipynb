{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4caf0959",
   "metadata": {},
   "source": [
    "# Fraudulent User Detection Using Amazon Dataset\n",
    "### Penghao Xu, Yuan Chen, Jiawei Wu, Haojing Lu\n",
    "\n",
    "## Part 1. Dataset preprocessing\n",
    "\n",
    "This script is used to clean the Amazon review dataset (http://jmcauley.ucsd.edu/data/amazon/links.html) and generate data for baseline and the new proposed model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f17224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bab77f",
   "metadata": {},
   "source": [
    "Download data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2688f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download data\n",
    "# !wget http://snap.stanford.edu/data/amazon/productGraph/kcore_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cd5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5-core data is used in this study\n",
    "# DO NOT extract the dataset. gzip format is required\n",
    "filename = 'kcore_5.json.gz'\n",
    "assert filename.endswith('gz'), 'Gzipped dataset is required!'\n",
    "\n",
    "# set output folder\n",
    "folder = 'dataset'\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7230faca",
   "metadata": {},
   "source": [
    "## 1. Generate rating-only dataset\n",
    "The rating-only dataset has 4 columns: User, item, and rating. This dataset is used for baseline model REV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32928253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000 reviews processed!\n"
     ]
    }
   ],
   "source": [
    "# Process data and generate helpfulness score\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_df(path, benign=0.8, fraudulent=0.2):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        i += 1\n",
    "        # report every 5m\n",
    "        if not i % 5000000:\n",
    "            print(f'{i} reviews processed!')\n",
    "        # skip if no helpful information\n",
    "        if not d['helpful'][1]:\n",
    "            continue\n",
    "        # extract useful features\n",
    "        df[i] = {}\n",
    "        for k in ['reviewerID', 'asin']:\n",
    "            df[i][k] = d[k]\n",
    "        df[i]['rating'] = (d['overall'] - 3) / 2\n",
    "        df[i]['helpfulness'] = d['helpful'][0]/d['helpful'][1]\n",
    "    df = pd.DataFrame.from_dict(df, orient='index')\n",
    "    return df\n",
    "df = get_df(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e076fe",
   "metadata": {},
   "source": [
    "Check the benign and fraudulent user counts in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dd728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = df.groupby('reviewerID').helpfulness.mean()\n",
    "benign = users[users > 0.8]\n",
    "fraudulent = users[users < 0.2]\n",
    "print(f'Benign users: {len(benign)}')\n",
    "print(f'Fraudulent users: {len(fraudulent)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c05ac7",
   "metadata": {},
   "source": [
    "Select only benign and fraudulent users. Discard the other users without label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = df[df.reviewerID.isin(set(benign.index))].copy()\n",
    "df_benign['label'] = 'Benign'\n",
    "df_fra = df[df.reviewerID.isin(set(fraudulent.index))].copy()\n",
    "df_fra['label'] = 'Fraudulent'\n",
    "df = pd.concat([df_benign, df_fra])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb003da",
   "metadata": {},
   "source": [
    "Check the number of reviews from benign and fraudulent users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851be3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(df.label)\n",
    "print(f'Reviews from benign users: {counts[\"Benign\"]}')\n",
    "print(f'Reviews from fraudulent users: {counts[\"Fraudulent\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30714b84",
   "metadata": {},
   "source": [
    "Generate k-core dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8176437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kcore(df, k):\n",
    "    # Repeatly remove the users with less than k reviews, \n",
    "    # then remove the items with less than k reviews until\n",
    "    # no one is removed.\n",
    "    diff = 1\n",
    "    while diff:\n",
    "        cache = len(df)\n",
    "        counts = df.groupby('reviewerID').asin.count()\n",
    "        counts = counts[counts >= k]\n",
    "        df = df[df.reviewerID.isin(set(counts.index))]\n",
    "        counts = df.groupby('asin').reviewerID.count()\n",
    "        counts = counts[counts >= k]\n",
    "        df = df[df.asin.isin(set(counts.index))]\n",
    "        diff = cache - len(df)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "split_rate = (0.4, 0.3, 0.3)\n",
    "output_base = f'{folder}/processed_{k}-core_80_20'\n",
    "\n",
    "# perform a random shuffle\n",
    "np.random.seed(3407)\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "# split\n",
    "dfs = {}\n",
    "n_train = int(len(df) * split_rate[0])\n",
    "n_val = int(len(df) * split_rate[1])\n",
    "dfs['train'] = df.iloc[:n_train]\n",
    "dfs['val'] = df.iloc[n_train:n_train+n_val]\n",
    "dfs['test'] = df.iloc[n_train+n_val:]\n",
    "dfs['all'] = df\n",
    "\n",
    "for curr in ('train', 'val', 'test', 'all'):\n",
    "    dfs[curr] = generate_kcore(dfs[curr], k)\n",
    "    df_out = dfs[curr][['reviewerID', 'asin', 'rating']]\n",
    "    df_out.to_csv(f'{output_base}_{curr}.csv', index=False)\n",
    "    df_out\n",
    "\n",
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9ba84",
   "metadata": {},
   "source": [
    "Check the number of reviews from benign and fraudulent users again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b25ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = {}\n",
    "fraudulent = {}\n",
    "for t in ['train', 'val', 'test', 'all']:\n",
    "    df = dfs[t]\n",
    "    benign[t] = set(df[df.label == 'Benign'].reviewerID.unique())\n",
    "    fraudulent[t] = set(df[df.label == 'Fraudulent'].reviewerID.unique())\n",
    "    print(t)\n",
    "    print(f'Benign users: {len(benign[t])}')\n",
    "    print(f'Fraudulent users: {len(fraudulent[t])}')\n",
    "    counts = Counter(df.label)\n",
    "    print(f'Reviews from benign users: {counts[\"Benign\"]}')\n",
    "    print(f'Reviews from fraudulent users: {counts[\"Fraudulent\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35a4fe",
   "metadata": {},
   "source": [
    "Output user labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42631388",
   "metadata": {},
   "outputs": [],
   "source": [
    "userfile_base = f'{folder}/user_label'\n",
    "for t in ['train', 'val', 'test', 'all']:\n",
    "    with open(userfile_base + f'_{t}.csv', 'w') as fw:\n",
    "        fw.write('reviewerID,fairness,label\\n')\n",
    "        for u in benign[t]:\n",
    "            fw.write(f'{u},{users[u]},Benign\\n')\n",
    "        for u in fraudulent[t]:\n",
    "            fw.write(f'{u},{users[u]},Fraudulent\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2baa593",
   "metadata": {},
   "source": [
    "## 2. Generate toy datasets for coding\n",
    "Here, toy datasets are generated to speed up model design and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select users\n",
    "n_benign = 50000\n",
    "n_fraudulent = 5000\n",
    "\n",
    "\n",
    "# output names\n",
    "toy_out_base = f'{folder}/toy_{k}-core_80_20'\n",
    "\n",
    "# generate toy train val and test data\n",
    "toys = {}\n",
    "benign['all'].sort()\n",
    "fraudulent['all'].sort()\n",
    "curr_benign = 0\n",
    "curr_fraudulent = 0\n",
    "for t in ['train', 'val', 'test']:\n",
    "    toy_users = set(benigh['all'][curr_benign:curr_benign+n_benign] + \\\n",
    "                        fraudulent['all'][curr_fraudulent:curr_fraudulent+n_fraudulent])\n",
    "    curr_benign += n_benign\n",
    "    curr_fraudulent += n_fraudulent\n",
    "    df = dfs['all']\n",
    "    toys[t] = df[df.reviewerID.isin(toy_users)].copy()\n",
    "    toys[t] = generate_kcore(toys[t], k)\n",
    "    df_toy_out = toys[t][['reviewerID', 'asin', 'rating']]\n",
    "    df_toy_out.to_csv(f'{toy_out_base}_{t}.csv', index=False)\n",
    "    toys[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f603fda",
   "metadata": {},
   "source": [
    "Statistics for toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a414f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_benign = {}\n",
    "toy_fraudulent = {}\n",
    "for t in ['train', 'val', 'test']:\n",
    "    toy_benign[t] = set(toys[t][toys[t].label == 'Benign'].reviewerID.unique())\n",
    "    toy_fraudulent[t] = set(toys[t][toys[t].label == 'Fraudulent'].reviewerID.unique())\n",
    "    print(t)\n",
    "    print(f'Benign users: {len(toy_benign[t])}')\n",
    "    print(f'Fraudulent users: {len(toy_fraudulent[t])}')\n",
    "    counts = Counter(toys[t].label)\n",
    "    print(f'Reviews from benign users: {counts[\"Benign\"]}')\n",
    "    print(f'Reviews from fraudulent users: {counts[\"Fraudulent\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126afe6",
   "metadata": {},
   "source": [
    "Output user labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_user_base = f'{folder}/toy_label'\n",
    "for t in ['train', 'val', 'test']:\n",
    "    with open(toy_user_base + f'_{t}.csv', 'w') as fw:\n",
    "        fw.write('reviewerID,fairness,label\\n')\n",
    "        for u in benign[t]:\n",
    "            fw.write(f'{u},{users[u]},Benign\\n')\n",
    "        for u in fraudulent[t]:\n",
    "            fw.write(f'{u},{users[u]},Fraudulent\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c00632",
   "metadata": {},
   "source": [
    "## 3. Generate dataset with text reviews\n",
    "\n",
    "Here, we generate the dataset with text reviews of same review, which can help us to incorporate text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e969110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output name\n",
    "output_base = f'{folder}/processed_{k}-core_80_20'\n",
    "output_toy_base = f'{folder}/toy_{k}-core_80_20'\n",
    "\n",
    "# Only output the reviews from selected entries for processed dataset\n",
    "products = {}\n",
    "reviewers = {}\n",
    "fws = {}\n",
    "for t in ['train', 'val', 'test', 'all']:\n",
    "    products[t] = set(dfs[t].asin.unique())\n",
    "    reviewers[t] = set(dfs[t].reviewerID.unique())\n",
    "    fws[t] = open(f'{output_base}_{t}_with_text.csv', 'w')\n",
    "    fws[t].write('reviewerID,asin,rating,reviewText\\n')\n",
    "    \n",
    "# toy dataset\n",
    "toy_products = {}\n",
    "toy_reviewers = {}\n",
    "toy_fws = {}\n",
    "for t in ['train', 'val', 'test']:\n",
    "    toy_products[t] = set(toys[t].asin.unique())\n",
    "    toy_reviewers[t] = set(toys[t].reviewerID.unique())\n",
    "    toy_fws[t] = open(f'{output_toy_base}_{t}_with_text.csv', 'w')\n",
    "    toy_fws[t].write('reviewerID,asin,rating,reviewText\\n')\n",
    "\n",
    "# check all reviews\n",
    "i=0\n",
    "for d in parse(filename):\n",
    "    i += 1\n",
    "    # report every 5m\n",
    "    if not i % 5000000:\n",
    "        print(f'{i} reviews processed!')\n",
    "    if not d['helpful'][1]:\n",
    "        continue\n",
    "    for t in ['train', 'val', 'test', 'all']:\n",
    "        if d['reviewerID'] in reviewers[t] and d['asin'] in products[t]:\n",
    "            fws[t].write(','.join([d['reviewerID'], d['asin'], str((d['overall']-3)/2), \\\n",
    "                           d['reviewText'].replace('\\n',' ').replace(',', ' ')]) + '\\n')\n",
    "    for t in ['train', 'val', 'test']:\n",
    "        if d['reviewerID'] in toy_reviewers[t] and d['asin'] in toy_products[t]:\n",
    "            toy_fws[t].write(','.join([d['reviewerID'], d['asin'], str((d['overall']-3)/2), \\\n",
    "                           d['reviewText'].replace('\\n',' ').replace(',', ' ')]) + '\\n')\n",
    "\n",
    "# close files\n",
    "for fw in fws.values():\n",
    "    fw.close()\n",
    "for fw in toy_fws.values():\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f2a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
