{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b530c834",
   "metadata": {},
   "source": [
    "# Fraudulent User Detection Using Amazon Dataset\n",
    "### Penghao Xu, Yuan Chen, Jiawei Wu, Haojing Lu\n",
    "\n",
    "## Part 3. Proposed New Methods\n",
    "\n",
    "This script is used to apply our proposed new model to fraudulent user detection on Amazon review dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b413c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ae10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = f'dataset/toy_3-core_80_20_test_embedding.csv'\n",
    "labelfile = f'dataset/toy_user_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b72d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check cuda availablity\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfd532",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Here, we load all scores and embeddings and group them in each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2a9b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 12734\n",
      "tensor(0.8889, device='cuda:0')\n",
      "Total products: 18525\n",
      "[['A14CC5FIPR5YVF', '0001055178', tensor([0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])], ['A19D816DMGI44L', '0001055178', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])], ['A12RI2CLUGCZ26', '0001055178', tensor([0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])]]\n"
     ]
    }
   ],
   "source": [
    "# load labels and sort in users order\n",
    "with open(labelfile, 'r') as fr:\n",
    "    fr.readline()\n",
    "    user_labels = []\n",
    "    for l in fr:\n",
    "        ws = l.rstrip('\\n').split(',')\n",
    "        user_labels.append((ws[0], float(ws[1])))\n",
    "    user_labels.sort()\n",
    "    user_labels = torch.tensor([x[1] for x in user_labels]).to(device)\n",
    "\n",
    "# load data and group by products\n",
    "with open(datafile, 'r') as fr:\n",
    "    data = {}\n",
    "    for l in fr:\n",
    "        ws = l.rstrip('\\n').split(',')\n",
    "        emb_dim = len(ws) - 2\n",
    "        if ws[1] not in data:\n",
    "            data[ws[1]] = []\n",
    "        data[ws[1]].append([ws[0], ws[1], torch.tensor([float(x) for x in ws[2:]])])\n",
    "print(f'Total users: {len(user_labels)}')\n",
    "print(user_labels[0])\n",
    "print(f'Total products: {len(data)}')\n",
    "print(data['0001055178'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872fb17",
   "metadata": {},
   "source": [
    "### Build model\n",
    "This model takes the text embeddings and scores to predict the user helpfulness and detect fraudulent users using the following formula:\n",
    "\n",
    "$$\n",
    "\\overrightarrow{G(p)} = AGG(RNN(\\overrightarrow{S(u, p)}, \\forall u \\in U),  \\Pi_p)\n",
    "$$\n",
    "$$\n",
    "\\overrightarrow{R(u, p)} = NN(\\overrightarrow{S(u, p)}, \\overrightarrow{G(p)})\n",
    "$$\n",
    "$$\n",
    "F(u) = AGG(\\overrightarrow{R(u, p)}, \\forall p \\in P, \\overrightarrow{\\Pi_u}) \n",
    "$$\n",
    "\n",
    "In this very first model, the product and user embeddings are removed. We used the following formula:\n",
    "$$\n",
    "\\overrightarrow{G(p)} = GRU(\\overrightarrow{S(u, p)}, \\forall u \\in U)\n",
    "$$\n",
    "$$\n",
    "\\overrightarrow{R(u, p)} = NN(\\overrightarrow{S(u, p)}, \\overrightarrow{G(p)})\n",
    "$$\n",
    "$$\n",
    "F(u) = GRU(\\overrightarrow{R(u, p)}, \\forall p \\in P) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3106918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "           1.0000]],\n",
       " \n",
       "         [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "           1.0000]],\n",
       " \n",
       "         [[0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "           1.0000]]]),\n",
       " '0001055178')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function to convert text embeddings of a product\n",
    "def emb2tensor(data, dim):\n",
    "    product = data[0][1]\n",
    "    tensor = torch.zeros((len(data), 1, dim))\n",
    "    for i, d in enumerate(data):\n",
    "        tensor[i,:,:] = d[-1]\n",
    "    return tensor, product\n",
    "emb2tensor(data['0001055178'], emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55cd6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FUD(nn.Module):\n",
    "    def __init__(self, emb_dim, device):\n",
    "        super().__init__()\n",
    "        # get parameters\n",
    "        self.dim = emb_dim\n",
    "        # set layers\n",
    "        self.GRU = nn.GRU(emb_dim, 32)\n",
    "        self.fc1 = nn.Linear(emb_dim + 32, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.GRU2 = nn.GRU(16, 1)\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # calculate gp\n",
    "        gp = {}\n",
    "        for su in x.values():\n",
    "            tensor, p = emb2tensor(su, self.dim)\n",
    "            gp[p] = self.GRU(tensor.to(self.device))[-1].view(-1)\n",
    "        # calculate rup\n",
    "        rup = {}\n",
    "        for su in x.values():\n",
    "            for r in su:\n",
    "                u, p, s = r\n",
    "                s = torch.cat((s.to(device), gp[p]))\n",
    "                if u not in rup:\n",
    "                    rup[u] = []\n",
    "                rup[u].append(self.fc2(F.relu(self.fc1(s))))\n",
    "        # fairness for users\n",
    "        fu = []\n",
    "        for u in sorted(rup.keys()):\n",
    "            v = torch.stack(rup[u], dim=1).view(len(rup[u]), 1, 16)\n",
    "            fu.append(self.GRU2(v)[-1])\n",
    "        return torch.cat(fu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932eac6",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4db3a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FUD(\n",
       "  (GRU): GRU(9, 32)\n",
       "  (fc1): Linear(in_features=41, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (GRU2): GRU(16, 1)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FUD(emb_dim, device).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ed7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE Loss: 0.4592105746269226\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=1e-7)\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 50\n",
    "report_epoch = 5\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    y_pred = model(data)\n",
    "    loss = criterion(y_pred.view(-1), user_labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.view(-1).cpu().detach().numpy()[0])\n",
    "    if not i % report_epoch:\n",
    "        print(f'Epoch {i}, MSE Loss: {losses[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1d228",
   "metadata": {},
   "source": [
    "Save model weights if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Model_weights.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe1c24",
   "metadata": {},
   "source": [
    "Visualize training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee45bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.set(style='ticks', font_scale=2)\n",
    "plt.plot(list(range(epochs)), losses)\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Training process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959edcd",
   "metadata": {},
   "source": [
    "Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels\n",
    "labels = user_labels.cpu().detach().numpy()\n",
    "labels[labels>0.5] = 1\n",
    "labels[labels<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea7806",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "preds = y_pred.view(-1).cpu().detach().numpy()\n",
    "preds[preds > threshold] = 1\n",
    "preds[preds < threshold] = 0\n",
    "acc = np.sum(preds == labels)/len(preds)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22016d",
   "metadata": {},
   "source": [
    "ROC curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52804a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(labels, y_pred.view(-1).cpu().detach().numpy())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.set(style='ticks', font_scale=2)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.title(f'ROC curve\\n AUC:{roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085ed3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
